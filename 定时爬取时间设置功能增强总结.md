# 定时爬取时间设置功能增强总结

## 功能概述

根据用户需求，在Settings.vue页面中增强了定时爬取功能，现在用户可以详细设置每个爬虫的爬取时间和爬取频率。

## 新增功能

### 1. 增强的时间选择器

#### 1.1 预设时间选项
- **每天执行**：从凌晨1点到晚上10点，每30分钟一个选项
- **每小时执行**：每小时整点或30分执行
- **每30分钟执行**：每30分钟执行一次
- **每周执行**：每周一到周日的凌晨2点执行

#### 1.2 自定义时间设置
- 点击"自定义"按钮打开高级时间设置模态框
- 支持多种执行频率：每天、每周、每月、每小时
- 可视化时间选择器
- 实时预览执行时间

### 2. 爬取参数设置

#### 2.1 可配置参数
- **批次大小**：每次爬取的数据条数（1-1000）
- **最大记录数**：单次任务最大爬取记录数（1-10000）
- **重试次数**：失败时的重试次数（0-10）
- **超时时间**：请求超时时间（10-300秒）
- **延迟时间**：请求间隔时间（0-60秒）

#### 2.2 参数建议
- 批次大小：建议10-100，数值过大会影响性能
- 最大记录数：建议100-1000，数值过大会增加执行时间
- 重试次数：建议3-5次，避免过度重试
- 超时时间：建议30-120秒，根据网络情况调整
- 延迟时间：建议1-5秒，避免对目标网站造成压力

### 3. 用户界面优化

#### 3.1 表格操作
- 每个爬虫配置都有独立的操作按钮
- **手动触发**：立即执行爬虫任务
- **参数**：设置爬取参数
- **详情**：查看爬虫详细信息

#### 3.2 状态显示
- 实时显示爬虫执行状态
- 颜色编码：成功(绿色)、失败(红色)、运行中(蓝色)、等待中(橙色)、已取消(灰色)
- 显示最后执行时间和执行次数

#### 3.3 统计信息
- 总配置数统计
- 启用/禁用配置数统计
- 按模块和国家分类统计

## 技术实现

### 1. 前端组件

#### 1.1 时间选择器组件
```vue
<a-select v-model:value="record.cronExpression">
  <a-select-option-group label="每天执行">
    <a-select-option value="0 0 1 * * ?">每天凌晨1点</a-select-option>
    <!-- 更多时间选项 -->
  </a-select-option-group>
</a-select>
```

#### 1.2 自定义时间模态框
```vue
<a-modal v-model:open="customCronModal.visible" title="自定义执行时间">
  <a-form layout="vertical">
    <a-form-item label="执行频率">
      <a-radio-group v-model:value="customCronModal.frequency">
        <a-radio value="daily">每天</a-radio>
        <a-radio value="weekly">每周</a-radio>
        <!-- 更多频率选项 -->
      </a-radio-group>
    </a-form-item>
  </a-form>
</a-modal>
```

#### 1.3 参数设置模态框
```vue
<a-modal v-model:open="crawlerParamsModal.visible" title="爬取参数设置">
  <a-form layout="vertical">
    <a-form-item label="批次大小">
      <a-input-number v-model:value="crawlerParamsModal.batchSize" :min="1" :max="1000" />
    </a-form-item>
    <!-- 更多参数设置 -->
  </a-form>
</a-modal>
```

### 2. 后端API

#### 2.1 配置管理API
- `GET /api/scheduled-crawlers` - 获取所有爬虫配置
- `PUT /api/scheduled-crawlers/{id}` - 更新爬虫配置
- `POST /api/scheduled-crawlers/{id}/toggle` - 切换爬虫启用状态

#### 2.2 手动触发API
- `POST /api/scheduled-crawlers/trigger/certnewsdata/{crawlerName}` - 触发CertNewsData爬虫
- `POST /api/scheduled-crawlers/trigger/devicedata/{crawlerName}` - 触发设备数据爬虫

#### 2.3 统计信息API
- `GET /api/scheduled-crawlers/statistics` - 获取爬虫统计信息

### 3. 数据库设计

#### 3.1 配置表结构
```sql
CREATE TABLE t_scheduled_crawler_config (
  id BIGINT AUTO_INCREMENT PRIMARY KEY,
  crawler_name VARCHAR(100) NOT NULL UNIQUE,
  module_name VARCHAR(50) NOT NULL,
  country_code VARCHAR(10),
  cron_expression VARCHAR(50) NOT NULL,
  enabled BOOLEAN NOT NULL DEFAULT TRUE,
  crawl_params TEXT,
  last_execution_time DATETIME,
  last_execution_status VARCHAR(20),
  last_execution_message TEXT,
  execution_count BIGINT DEFAULT 0,
  created_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  deleted INT DEFAULT 0
);
```

#### 3.2 默认配置
系统会自动创建以下默认配置：
- **CertNewsData模块**：SGS、UL、Beice爬虫
- **美国设备数据**：510K、事件报告、召回记录、注册记录
- **欧盟设备数据**：召回记录、注册记录、指导文档、海关案例

## 使用说明

### 1. 设置爬取时间

#### 1.1 使用预设时间
1. 在Settings页面找到"定时爬取设置"选项卡
2. 选择对应的模块（认证新闻数据/设备数据）
3. 在"执行时间"列选择预设的时间选项
4. 系统会自动保存配置

#### 1.2 自定义时间
1. 点击"自定义"按钮
2. 选择执行频率（每天/每周/每月/每小时）
3. 设置具体时间
4. 查看预览信息
5. 点击"确定"保存

### 2. 设置爬取参数

1. 点击爬虫配置行的"参数"按钮
2. 设置各项参数值
3. 查看参数建议
4. 点击"确定"保存

### 3. 监控爬虫状态

1. 在配置表格中查看"执行状态"列
2. 查看"最后执行时间"和"执行次数"
3. 使用"手动触发"按钮测试爬虫
4. 在"统计信息"选项卡查看整体统计

## 配置示例

### 1. 高频爬取配置
```json
{
  "cronExpression": "0 */30 * * * ?",
  "crawlParams": {
    "batchSize": 20,
    "maxRecords": 100,
    "retryCount": 3,
    "timeout": 30,
    "delay": 2
  }
}
```

### 2. 低频爬取配置
```json
{
  "cronExpression": "0 0 2 * * ?",
  "crawlParams": {
    "batchSize": 100,
    "maxRecords": 1000,
    "retryCount": 5,
    "timeout": 120,
    "delay": 5
  }
}
```

### 3. 每周爬取配置
```json
{
  "cronExpression": "0 0 2 ? * MON",
  "crawlParams": {
    "batchSize": 200,
    "maxRecords": 2000,
    "retryCount": 3,
    "timeout": 180,
    "delay": 3
  }
}
```

## 注意事项

### 1. 性能考虑
- 批次大小不宜过大，避免内存溢出
- 延迟时间设置合理，避免对目标网站造成压力
- 超时时间根据网络情况调整

### 2. 资源管理
- 高频爬取会消耗更多系统资源
- 建议在系统负载较低时执行爬取任务
- 监控系统资源使用情况

### 3. 错误处理
- 设置合理的重试次数
- 监控爬虫执行状态
- 及时处理失败的爬取任务

## 扩展功能

### 1. 计划中的功能
- 爬虫执行日志查看
- 爬取数据量统计
- 异常告警通知
- 爬虫性能分析

### 2. 可扩展性
- 支持更多时间格式
- 支持条件执行
- 支持爬虫依赖关系
- 支持分布式爬取

## 总结

通过这次功能增强，用户现在可以：

1. **灵活设置爬取时间**：从简单的预设选项到复杂的自定义时间配置
2. **精细控制爬取参数**：根据实际需求调整各项参数
3. **实时监控爬虫状态**：随时了解爬虫执行情况
4. **统一管理配置**：在一个界面中管理所有爬虫配置

这些功能大大提升了系统的可用性和灵活性，让用户能够根据实际业务需求来配置和管理定时爬取任务。


